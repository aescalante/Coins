{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "<body>\n",
    "<h1 style = \"color:blue\"> Classify 10, 20 & 50 cent coins into two different categories</h1>\n",
    "\n",
    "<h2 style = \"color:red\"> Abstract: </h2>\n",
    "<p>The goal of this notebook is to build a convNN clasification using Tensor Flow library that is desinged to classify a given image of an euro coin into three different categories:.</p>\n",
    "<p> a) Categorie 0 = 10 cents. </p>\n",
    "<p> b) Categorie 1 = 20 cents. </p>\n",
    "<p> c) Categorie 2 = 50 cents.\n",
    "\n",
    "<h2 style = \"color:red\"> Dataset: </h2>\n",
    "<p>The dataset employed in the training process is given by the Euro Coin dataset.</p>\n",
    "</body>\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, cv2, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from coins_utils import *\n",
    "\n",
    "TRAIN_DIR = 'CandidateDataSet2/augmented_and_resized_brightness_yuv_RAW/50centVs20centVs10cent/'\n",
    "#TRAIN_DIR = 'CandidateDataSet2/augmented_and_resized_RAW/50centVs20centVs10cent/'\n",
    "\n",
    "images_full = [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR) if '.jpg' in i]\n",
    "random.shuffle(images_full)\n",
    "n_images = len(images_full)\n",
    "print(\"Number of images in full dataset \"+str(n_images))\n",
    "print(\"------------------------------------\")\n",
    "\n",
    "\n",
    "#Splitting of the input dataset into train, validation and test set.\n",
    "train_to_full = 0.3 # Fraction of images used for training\n",
    "validation_to_full = 0.8 # Fraction of images used for validation\n",
    "train_to_full_index = int(n_images*train_to_full)\n",
    "validation_to_full_index = int(n_images*validation_to_full)\n",
    "\n",
    "#train_images = sorted(images_full[:train_to_full_index])\n",
    "#validation_images =  sorted(images_full[train_to_full_index:validation_to_full_index])\n",
    "#test_images =  sorted(images_full[validation_to_full_index:])\n",
    "\n",
    "train_images = images_full[:train_to_full_index]\n",
    "validation_images =  images_full[train_to_full_index:validation_to_full_index]\n",
    "test_images =  images_full[validation_to_full_index:]\n",
    "\n",
    "n_train_images = len(train_images)\n",
    "n_validation_images = len(validation_images)\n",
    "n_test_images = len(test_images)\n",
    "\n",
    "print(\"Total number of train images \"+str(n_train_images))\n",
    "print(\"Total number of validation images \"+str(n_validation_images))\n",
    "print(\"Total number of test images \"+str(n_test_images))\n",
    "if n_train_images+n_validation_images+n_test_images - n_images != 0:\n",
    "    print(\"Warning, there is a problem in the splitting of images\")\n",
    "\n",
    "train = prep_data(train_images, colorSpace = \"YUV\")\n",
    "validation = prep_data(validation_images, colorSpace = \"YUV\")\n",
    "test = prep_data(test_images, colorSpace = \"YUV\")\n",
    "\n",
    "#To make them easier to operate in future\n",
    "train_images_name = [i.split('/')[-1] for i in train_images]\n",
    "validation_images_name = [i.split('/')[-1] for i in validation_images]\n",
    "test_images_name = [i.split('/')[-1] for i in test_images]\n",
    "print(len(train_images_name), len(validation_images_name), len(test_images_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## read the labels.\n",
    "labels = pd.read_csv(TRAIN_DIR+'/labels_50centVs20centVs10cent.csv')\n",
    "\n",
    "labels_train_df = labels[labels[\"FileName\"].isin(train_images_name)]\n",
    "labels_validation_df = labels[labels[\"FileName\"].isin(validation_images_name)]\n",
    "labels_test_df = labels[labels[\"FileName\"].isin(test_images_name)]\n",
    "\n",
    "\n",
    "#Example get the CoinType field and create array with labels (This is not very efficient...)\n",
    "#iloc is there because for some reason it won't give me values with 'CoinType'.\n",
    "nb_classes = 3\n",
    "labels_train_nocategorical = []\n",
    "for kitem in train_images_name:\n",
    "        labels_train_nocategorical.append(labels[labels[\"FileName\"] == kitem].iloc[0][3])   \n",
    "labels_train_nocategorical= np.array(labels_train_nocategorical)\n",
    "    \n",
    "labels_validation_nocategorical = []\n",
    "for kitem in validation_images_name:\n",
    "        labels_validation_nocategorical.append(labels[labels[\"FileName\"] == kitem].iloc[0][3]) \n",
    "labels_validation_nocategorical= np.array(labels_validation_nocategorical)\n",
    "\n",
    "\n",
    "labels_test_nocategorical = []\n",
    "for kitem in test_images_name:\n",
    "        labels_test_nocategorical.append(labels[labels[\"FileName\"] == kitem].iloc[0][3])     \n",
    "labels_test_nocategorical= np.array(labels_test_nocategorical)\n",
    "\n",
    "\n",
    "#Convert to categorical labels (vectors)\n",
    "from keras.utils import np_utils\n",
    "labels_train = np_utils.to_categorical(labels_train_nocategorical, nb_classes)\n",
    "labels_validation = np_utils.to_categorical(labels_validation_nocategorical, nb_classes)\n",
    "labels_test = np_utils.to_categorical(labels_test_nocategorical, nb_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity check, we are reading everything properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Print some coins\n",
    "def printSomeCoints(img, train_images_name, labels, ncoins):\n",
    "    for i in range(0,ncoins):\n",
    "        print(train_images_name[i])\n",
    "        if labels[i] == 0.:\n",
    "            print(\"This is 10 cent\")\n",
    "        if labels[i] == 1.:\n",
    "            print(\"This is 20 cent\")\n",
    "        if labels[i] == 2.:\n",
    "            print(\"This is 50 cent\")\n",
    "        plt.figure(figsize=(10,5))\n",
    "        print(train[i].shape)\n",
    "        plt.imshow(cv2.cvtColor(train[i], cv2.COLOR_YUV2RGB))\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "printSomeCoints(train, train_images_name, labels_train_nocategorical, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "<body>\n",
    "<h2 style = \"color:red\"> Building the classificator (work in progress..): </h2>\n",
    "<p> Use the training dataset to build the classificator using a ConvNN.</p>\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Loading keras deep learnig libraries to build the model: https://keras.io/ \n",
    "from keras.layers import Input, Dense, Flatten, Dropout, Activation, advanced_activations, Convolution2D, MaxPooling2D\n",
    "from keras.models import Model, model_from_json\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras import initializations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Model hyperparameters\n",
    "batch_size = 32 # in each iteration, we consider batch_size training examples at once\n",
    "num_epochs = 15 # we iterate num_epochs times over the entire training set\n",
    "kernel_size = 3 # we will use 3x3 kernels throughout\n",
    "pool_size = 2 # we will use 2x2 pooling throughout\n",
    "conv_depth_1 = 32 # we will initially have 32 kernels per conv. layer...\n",
    "conv_depth_2 = 62 # ...switching to 64 after the first pooling layer\n",
    "conv_depth_3 = 128 # ...switching to 64 after the first pooling layer\n",
    "conv_depth_4 = 256 # ...switching to 64 after the first pooling layer\n",
    "conv_depth_5 = 512 # ...switching to 64 after the first pooling layer\n",
    "drop_prob_1 = 0.25 # dropout after pooling with this probability \n",
    "drop_prob_2 = 0.5 # dropout in the FC layer with this probability \n",
    "hidden_size = 64 # the FC layer will this neurons\n",
    "data_augmentation = False # Whether to use or not data augmentation\n",
    "\n",
    "ROWS = 100\n",
    "COLS = 100\n",
    "CHANNELS = 3\n",
    "\n",
    "NN = False\n",
    "ConvNN = True\n",
    "if ConvNN == True:\n",
    "    #Architecture\n",
    "    inp = Input(shape=(ROWS, COLS, CHANNELS)) # N.B. depth goes first in Keras!\n",
    "    conv_1 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='tanh')(inp)\n",
    "    pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_1)\n",
    "    conv_2 = Convolution2D(conv_depth_2, kernel_size, kernel_size, border_mode='same', activation='tanh')(pool_1)\n",
    "    pool_2 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_2)\n",
    "    conv_3 = Convolution2D(conv_depth_3, kernel_size, kernel_size, border_mode='same', activation='tanh')(pool_2)\n",
    "    #pool_3 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_3)\n",
    "    #conv_4 = Convolution2D(conv_depth_4, kernel_size, kernel_size, border_mode='same', activation='tanh')(pool_3)\n",
    "    #pool_4 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_4)\n",
    "    #conv_5 = Convolution2D(conv_depth_5, kernel_size, kernel_size, border_mode='same', activation='tanh')(pool_4)\n",
    "                       \n",
    "\n",
    "    flat = Flatten()(conv_3)\n",
    "    hidden = Dense(hidden_size, activation='tanh')(flat)\n",
    "    out = Dense(nb_classes, activation='sigmoid')(hidden)\n",
    "    model = Model(input=inp, output=out) # To define a model, just specify its input and output layers\n",
    "\n",
    "if NN == True:\n",
    "    #Architecture\n",
    "    inp = Input(shape=(ROWS, COLS, CHANNELS)) # N.B. depth goes first in Keras!                  \n",
    "    flat = Flatten()(inp)\n",
    "    hidden = Dense(hidden_size, activation='tanh')(flat)\n",
    "    out = Dense(nb_classes, activation='sigmoid')(hidden)\n",
    "    model = Model(input=inp, output=out) # To define a model, just specify its input and output layers\n",
    "\n",
    "    \n",
    "#print the summary of the architecture\n",
    "model.summary()\n",
    "\n",
    "#Visulize the model if desired\n",
    "#from keras.utils.visualize_util import plot\n",
    "#plot(model, to_file='Example_of_CNN_CatsVsDogs.pdf')\n",
    "\n",
    "# reduce the learning rate by factor of 0.5 if the validation loss does not get lower in 7 epochs\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=0.0000001, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')\n",
    "\n",
    "\n",
    "# Let's train the model using SGD\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='adagrad', metrics=['accuracy'])\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=1e-4), metrics=['accuracy'])\n",
    "\n",
    "# Let's train the SGD model WITHOUT using data augmentation\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    history = model.fit(train, labels_train, batch_size=batch_size, nb_epoch=num_epochs, validation_data=(validation, labels_validation), shuffle=True, callbacks=[reduce_lr,early_stopping])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduced (And deeper) architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Model hyperparameters\n",
    "batch_size = 32 # in each iteration, we consider batch_size training examples at once\n",
    "num_epochs = 100 # we iterate num_epochs times over the entire training set\n",
    "kernel_size = 3 # we will use 3x3 kernels throughout\n",
    "pool_size = 2 # we will use 2x2 pooling throughout\n",
    "conv_depth_1 = 8\n",
    "conv_depth_2 = 16\n",
    "conv_depth_3 = 32\n",
    "conv_depth_4 = 64\n",
    "conv_depth_5 = 64\n",
    "conv_depth_6 = 64\n",
    "conv_depth_7 = 128\n",
    "conv_depth_8 = 128\n",
    "#conv_depth_1 = 32 # we will initially have 32 kernels per conv. layer...\n",
    "#conv_depth_2 = 62 # ...switching to 64 after the first pooling layer\n",
    "#conv_depth_3 = 128 # ...switching to 64 after the first pooling layer\n",
    "#conv_depth_4 = 256 # ...switching to 64 after the first pooling layer\n",
    "#conv_depth_5 = 512 # ...switching to 64 after the first pooling layer\n",
    "drop_prob_1 = 0.25 # dropout after pooling with this probability \n",
    "drop_prob_2 = 0.5 # dropout in the FC layer with this probability \n",
    "hidden_size = 24 # the FC layer will this neurons\n",
    "data_augmentation = False # Whether to use or not data augmentation\n",
    "\n",
    "ROWS = 100\n",
    "COLS = 100\n",
    "CHANNELS = 3\n",
    "\n",
    "NN = False\n",
    "ConvNN = True\n",
    "if ConvNN == True:\n",
    "    #Architecture\n",
    "    inp = Input(shape=(ROWS, COLS, CHANNELS)) # N.B. depth goes first in Keras!\n",
    "    conv_1 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='tanh')(inp)\n",
    "    pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_1)\n",
    "    conv_2 = Convolution2D(conv_depth_2, kernel_size, kernel_size, border_mode='same', activation='tanh')(pool_1)\n",
    "    pool_2 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_2)\n",
    "    pool_2_d = Dropout(drop_prob_1)(pool_2)\n",
    "    conv_3 = Convolution2D(conv_depth_3, kernel_size, kernel_size, border_mode='same', activation='tanh')(pool_2_d)\n",
    "    pool_3 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_3)\n",
    "    pool_3_d = Dropout(drop_prob_1)(pool_3)\n",
    "    conv_4 = Convolution2D(conv_depth_4, kernel_size, kernel_size, border_mode='same', activation='tanh')(pool_3_d)\n",
    "    #pool_4 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_4)\n",
    "    conv_5 = Convolution2D(conv_depth_5, kernel_size, kernel_size, border_mode='same', activation='tanh')(conv_4)\n",
    "    #pool_5 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_5)\n",
    "    conv_6 = Convolution2D(conv_depth_6, kernel_size, kernel_size, border_mode='same', activation='tanh')(conv_5)\n",
    "    #pool_6 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_6)\n",
    "    conv_7 = Convolution2D(conv_depth_7, kernel_size, kernel_size, border_mode='same', activation='tanh')(conv_6)\n",
    "    #pool_7 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_7)\n",
    "    #pool_7_d = Dropout(drop_prob_1)(pool_7)\n",
    "    conv_8 = Convolution2D(conv_depth_8, kernel_size, kernel_size, border_mode='same', activation='tanh')(conv_7)\n",
    "                       \n",
    "\n",
    "    flat = Flatten()(conv_8)\n",
    "    hidden = Dense(hidden_size, activation='tanh')(flat)\n",
    "    hidden_d = Dropout(drop_prob_2)(hidden)\n",
    "    out = Dense(nb_classes, activation='sigmoid')(hidden_d)\n",
    "    model = Model(input=inp, output=out) # To define a model, just specify its input and output layers\n",
    "\n",
    "if NN == True:\n",
    "    #Architecture\n",
    "    inp = Input(shape=(ROWS, COLS, CHANNELS)) # N.B. depth goes first in Keras!                  \n",
    "    flat = Flatten()(inp)\n",
    "    hidden = Dense(hidden_size, activation='tanh')(flat)\n",
    "    out = Dense(nb_classes, activation='sigmoid')(hidden)\n",
    "    model = Model(input=inp, output=out) # To define a model, just specify its input and output layers\n",
    "\n",
    "    \n",
    "#print the summary of the architecture\n",
    "model.summary()\n",
    "\n",
    "#Visulize the model if desired\n",
    "#from keras.utils.visualize_util import plot\n",
    "#plot(model, to_file='Example_of_CNN_CatsVsDogs.pdf')\n",
    "\n",
    "# reduce the learning rate by factor of 0.5 if the validation loss does not get lower in 7 epochs\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=0.0000001, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=8, verbose=1, mode='auto')\n",
    "\n",
    "\n",
    "# Let's train the model using SGD\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='adagrad', metrics=['accuracy'])\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=1e-4), metrics=['accuracy'])\n",
    "\n",
    "# Let's train the SGD model WITHOUT using data augmentation\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    history = model.fit(train, labels_train, batch_size=batch_size, nb_epoch=num_epochs, validation_data=(validation, labels_validation), shuffle=True, callbacks=[reduce_lr,early_stopping])\n",
    "                       \n",
    "                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning curves (check the performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig('Accuracy_Example_Coin_Classifier_GoldenCoins.pdf')\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig('Loss_Example_Coin_Classifier_GoldenCoins.pdf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#SaveModel(model, \"Model_Example_Coin_Classifier_GoldenCoins_Standard_yuv\") #For the standard architecture\n",
    "#SaveModel(model, \"Model_Example_Coin_Classifier_GoldenCoins_Reduced_yuv\") #For the reduced architecture\n",
    "SaveModel(model, \"Model_Example_Coin_Classifier_GoldenCoins_Deep_30p_dropout025_yuv\") #For the reduced deeper architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Useful to test.\n",
    "LoadAndTest = True\n",
    "nTest = 45\n",
    "if LoadAndTest == True:\n",
    "    #loaded_model=LoadModel(\"Model_Example_Coin_Classifier_GoldenCoins_Standard_yuv\") #For the standard architecture\n",
    "    #loaded_model=LoadModel(\"Model_Example_Coin_Classifier_GoldenCoins_Reduced_yuv\") #For the reduced architecture\n",
    "    loaded_model=LoadModel(\"Model_Example_Coin_Classifier_GoldenCoins_Deep_30p_dropout025_yuv\") #For the reduced deeper architecture\n",
    "    # evaluate loaded model on test data\n",
    "    loaded_model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=1e-4), metrics=['accuracy'])\n",
    "    \n",
    "    #score_train = loaded_model.evaluate(train, labels_train, verbose=0)\n",
    "    #score_validation = loaded_model.evaluate(validation, labels_validation, verbose=0)\n",
    "    #print \"Training %s: %.2f%%\" % (loaded_model.metrics_names[1], score_train[1]*100)\n",
    "    #print \"Validation %s: %.2f%%\" % (loaded_model.metrics_names[1], score_validation[1]*100)    \n",
    "    \n",
    "    print(\"PREDICTIONS \\n\")\n",
    "    reduced_test = test[:nTest]\n",
    "    predictedLabel = loaded_model.predict(reduced_test)\n",
    "\n",
    "    for i in range(0,nTest):\n",
    "        print(\" %.8f of 10 cents \\n\" % predictedLabel[i,0])\n",
    "        print(\" %.8f of 20 cents \\n\" % predictedLabel[i,1])\n",
    "        print(\" %.8f of 50 cents \\n\" % predictedLabel[i,2])\n",
    "\n",
    "        plt.imshow(cv2.cvtColor(reduced_test[i], cv2.COLOR_YUV2RGB))\n",
    "        plt.show()\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Testing with mixed coins images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Useful to test.\n",
    "TEST_DIR = 'CandidateDataSet2/Processed_RAW/mix/'\n",
    "#input_file = glob.glob(TEST_DIR+\"*.jpg\") #Try new Samples\n",
    "input_file = [TEST_DIR+\"P70216-160609_Candidate_6.jpg\"]  #For debugging\n",
    "print(\"--- 10 cents ---\")\n",
    "input_file.append(TEST_DIR+\"P70216-160642_Candidate_10.jpg\")\n",
    "input_file.append(TEST_DIR+\"P70216-160642_Candidate_20.jpg\")\n",
    "input_file.append(TEST_DIR+\"P70216-160642_Candidate_21.jpg\")\n",
    "input_file.append(TEST_DIR+\"P70216-160652_Candidate_27.jpg\")\n",
    "input_file.append(TEST_DIR+\"P70216-160652_Candidate_25.jpg\")\n",
    "input_file.append(TEST_DIR+\"P70216-160652_Candidate_26.jpg\")\n",
    "input_file.append(TEST_DIR+\"P70216-160813_Candidate_37.jpg\")\n",
    "input_file.append(TEST_DIR+\"P70216-161849_Candidate_4.jpg\")\n",
    "input_file.append(TEST_DIR+\"P70216-161849_Candidate_18.jpg\")\n",
    "input_file.append(TEST_DIR+\"P70216-161000_Candidate_34.jpg\")\n",
    "input_file.append(TEST_DIR+\"P70216-160854_Candidate_38.jpg\")\n",
    "print(\"--- 10 cents : VALIDATION SET ---\")\n",
    "VAL_DIR = 'CandidateDataSet2/Processed_RAW/10cent/'\n",
    "input_file.append(VAL_DIR+\"P70216-134319_Candidate_14.jpg\")\n",
    "input_file.append(VAL_DIR+\"P70216-134504_Candidate_21.jpg\")\n",
    "input_file.append(VAL_DIR+\"P70216-134748_Candidate_5.jpg\")\n",
    "input_file.append(VAL_DIR+\"P70216-134440_Candidate_9.jpg\")\n",
    "input_file.append(VAL_DIR+\"P70216-134748_Candidate_9.jpg\")\n",
    "print(\"--- 20 cents ---\")\n",
    "input_file.append(TEST_DIR+\"P70216-160459_Candidate_5.jpg\")\n",
    "input_file.append(TEST_DIR+\"P70216-160524_Candidate_2.jpg\")\n",
    "input_file.append(TEST_DIR+\"P70216-160630_Candidate_9.jpg\")\n",
    "input_file.append(TEST_DIR+\"P70216-160630_Candidate_17.jpg\")\n",
    "input_file.append(TEST_DIR+\"P70216-160652_Candidate_7.jpg\")\n",
    "input_file.append(TEST_DIR+\"P70216-160813_Candidate_8.jpg\")\n",
    "input_file.append(TEST_DIR+\"P70216-160854_Candidate_7.jpg\")\n",
    "input_file.append(TEST_DIR+\"P70216-160854_Candidate_29.jpg\")\n",
    "input_file.append(TEST_DIR+\"P70216-160652_Candidate_7.jpg\")\n",
    "print(\"--- 20 cents : VALIDATION SET ---\")\n",
    "VAL_DIR = 'CandidateDataSet2/Processed_RAW/20cent/'\n",
    "input_file.append(VAL_DIR+\"P70210-172818_Candidate_14.jpg\")\n",
    "input_file.append(VAL_DIR+\"P70210-172835_Candidate_1.jpg\")\n",
    "input_file.append(VAL_DIR+\"P70210-173008_Candidate_3.jpg\")\n",
    "input_file.append(VAL_DIR+\"P70210-173043_Candidate_15.jpg\")\n",
    "input_file.append(VAL_DIR+\"P70210-173134_Candidate_13.jpg\")\n",
    "print(\"--- 50 cents ---\")\n",
    "input_file.append(TEST_DIR+\"P70216-160459_Candidate_6.jpg\")\n",
    "input_file.append(TEST_DIR+\"P70216-160434_Candidate_5.jpg\")\n",
    "input_file.append(TEST_DIR+\"P70216-160549_Candidate_5.jpg\")\n",
    "input_file.append(TEST_DIR+\"P70216-160609_Candidate_6.jpg\")\n",
    "input_file.append(TEST_DIR+\"P70216-160630_Candidate_13.jpg\")\n",
    "input_file.append(TEST_DIR+\"P70216-160813_Candidate_24.jpg\")\n",
    "input_file.append(TEST_DIR+\"P70216-161000_Candidate_26.jpg\")\n",
    "input_file.append(TEST_DIR+\"P70216-161849_Candidate_13.jpg\")\n",
    "input_file.append(TEST_DIR+\"P70216-161845_Candidate_10.jpg\")\n",
    "print(\"--- 50 cents : VALIDATION SET ---\")\n",
    "VAL_DIR = 'CandidateDataSet2/Processed_RAW/50cent/'\n",
    "input_file.append(VAL_DIR+\"P70210-165438_Candidate_20.jpg\")\n",
    "input_file.append(VAL_DIR+\"P70210-165500_Candidate_7.jpg\")\n",
    "input_file.append(VAL_DIR+\"P70210-165718_Candidate_4.jpg\")\n",
    "input_file.append(VAL_DIR+\"P70210-165812_Candidate_3.jpg\")\n",
    "input_file.append(VAL_DIR+\"P70210-165858_Candidate_4.jpg\")\n",
    "LoadAndTest = True\n",
    "if LoadAndTest == True:\n",
    "    #loaded_model=LoadModel(\"Model_Example_Coin_Classifier_GoldenCoins_Standard_yuv\") #For the standard architecture\n",
    "    loaded_model=LoadModel(\"Model_Example_Coin_Classifier_GoldenCoins_Deep_30p_dropout025_yuv\") #For the reduced architecture\n",
    "    # evaluate loaded model on test data\n",
    "    #loaded_model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=1e-4), metrics=['accuracy'])\n",
    "    print(\"PREDICTIONS \\n\")\n",
    "    for kfile in input_file:\n",
    "        im = Image.open(kfile)\n",
    "        imarray = np.array(im)\n",
    "        imgResizedTest = cv2.resize(imarray, (ROWS, COLS), interpolation=cv2.INTER_CUBIC)\n",
    "        imgResizedTest = cv2.cvtColor(imgResizedTest, cv2.COLOR_RGB2YUV)\n",
    "        imgResizedTest = [imgResizedTest for i in range(0,1)]\n",
    "        imgResizedTest = np.array(imgResizedTest)        \n",
    "        predictedLabel = loaded_model.predict(imgResizedTest)\n",
    "        print(\" %.8f of 10 cent \\n\" % predictedLabel[0,0])\n",
    "        print(\" %.8f of 20 cent \\n\" % predictedLabel[0,1])\n",
    "        print(\" %.8f of 50 cent \\n\" % predictedLabel[0,2])\n",
    "        print(predictedLabel)\n",
    "        \n",
    "        #imgResizedTest = cv2.cvtColor(imgResizedTest[0], cv2.COLOR_YUV2BGR)\n",
    "        #imgResizedTest = cv2.cvtColor(imgResizedTest, cv2.COLOR_BGR2RGB)\n",
    "        plt.imshow(cv2.cvtColor(imgResizedTest[0], cv2.COLOR_YUV2RGB))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
